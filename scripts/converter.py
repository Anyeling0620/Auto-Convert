import json
import os
import uuid
import time
import requests
import random
import re
import datetime
from docx import Document
from zhipuai import ZhipuAI
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ================= ğŸ›¡ï¸ é…ç½®åŠ è½½ =================
CONFIG_FILE = "config.json"


def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


APP_CONFIG = load_config()
SUBJECT = APP_CONFIG.get("subject_name", "é€šç”¨å­¦ç§‘")
DESC = APP_CONFIG.get("description", "")
KEY_INDEX = APP_CONFIG.get("key_index", 0)
INPUT_DIR = "input"
OUTPUT_DIR = "output"
MAX_WORKERS = APP_CONFIG.get("max_workers", 16)

# ================= ğŸ”‘ ç¯å¢ƒä¸å¯†é’¥ =================
GITHUB_REF_NAME = os.getenv("GITHUB_REF_NAME", "local-dev")
GITHUB_REPOSITORY = os.getenv("GITHUB_REPOSITORY", "Local/Repo")
KEY_POOL_STR = os.getenv("ZHIPU_KEY_POOL", "")
PUSHPLUS_TOKEN = os.getenv("PUSHPLUS_TOKEN")


def get_api_key():
    if not KEY_POOL_STR: return None
    keys = [k.strip() for k in KEY_POOL_STR.split(',') if k.strip()]
    if not keys: return None
    if KEY_INDEX >= len(keys): return keys[0]
    return keys[KEY_INDEX]


ZHIPU_API_KEY = get_api_key()
AI_MODEL_NAME = "glm-4-flash"
CHUNK_SIZE = 2000;
OVERLAP = 200;
MAX_RETRIES = 5;
API_TIMEOUT = 120

if not ZHIPU_API_KEY:
    print("âŒ é”™è¯¯ï¼šæ— æ³•è·å– API Key")
    exit(1)

client = ZhipuAI(api_key=ZHIPU_API_KEY)


# ================= ğŸ“§ æŠ¥è¡¨æ¨é€æ¨¡å— =================
def send_report(data):
    if not PUSHPLUS_TOKEN: return

    is_success = data['failed_chunks'] == 0
    color = "#28a745" if is_success else "#dc3545"
    title = "âœ… é¢˜åº“ç”ŸæˆæˆåŠŸ" if is_success else "âš ï¸ ç”Ÿæˆå­˜åœ¨å¼‚å¸¸"

    html = f"""
    <div style="font-family:sans-serif; max-width:600px; padding:20px; border:1px solid #ddd; border-radius:8px;">
        <div style="border-bottom:2px solid {color}; padding-bottom:10px; margin-bottom:20px;">
            <h2 style="margin:0; color:#333;">{title}</h2>
            <p style="color:#666; font-size:12px; margin:5px 0;">{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}</p>
        </div>
        <div style="background:#f8f9fa; padding:10px; border-radius:4px; margin-bottom:15px; font-size:14px;">
            <p style="margin:4px 0;"><b>ğŸ“š å­¦ç§‘:</b> {SUBJECT}</p>
            <p style="margin:4px 0;"><b>ğŸŒ¿ åˆ†æ”¯:</b> {GITHUB_REF_NAME}</p>
            <p style="margin:4px 0;"><b>ğŸ¤– æ¨¡å‹:</b> {AI_MODEL_NAME}</p>
        </div>
        <ul style="padding-left:20px; margin-bottom:20px;">
            <li>â±ï¸ è€—æ—¶: <b>{data['duration']:.1f}s</b></li>
            <li>ğŸ“„ æ–‡ä»¶: {data['file_count']} ä¸ª</li>
            <li>ğŸ“ é¢˜ç›®: <b style="color:#007bff; font-size:16px;">{data['total_questions']}</b> é“</li>
            <li>ğŸ§© åˆ‡ç‰‡: æˆåŠŸ {data['success_chunks']} / å¤±è´¥ <b style="color:red;">{data['failed_chunks']}</b></li>
        </ul>
    """

    if data['errors']:
        html += "<div style='background:#fff3cd; padding:10px; border-radius:4px; border:1px solid #ffeeba;'>"
        html += "<h4 style='margin-top:0; color:#856404;'>âš ï¸ å¼‚å¸¸è¯¦æƒ…</h4><ul style='padding-left:20px; color:#856404; font-size:13px;'>"
        for err in data['errors']:
            html += f"<li style='margin-bottom:4px;'>{err}</li>"
        html += "</ul></div>"

    html += "</div>"

    requests.post("http://www.pushplus.plus/send", json={
        "token": PUSHPLUS_TOKEN, "title": f"[{SUBJECT}] ç”ŸæˆæŠ¥å‘Š", "content": html, "template": "html"
    }, timeout=5)


# ================= ğŸ› ï¸ æ ¸å¿ƒé€»è¾‘ =================
def read_docx(file_path):
    if not os.path.exists(file_path): return ""
    try:
        doc = Document(file_path)
        return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
    except:
        return ""


def get_chunks(text, size, overlap):
    chunks = [];
    start = 0;
    total = len(text)
    while start < total:
        end = min(start + size, total)
        chunks.append(text[start:end])
        if end == total: break
        start = end - overlap
    return chunks


def normalize_category(raw):
    if not raw: return "ç»¼åˆé¢˜"
    cat = raw.strip()
    if "A1" in cat: return "A1å‹é¢˜"
    if "A2" in cat: return "A2å‹é¢˜"
    if "B1" in cat: return "B1å‹é¢˜"
    if "Xå‹" in cat or "å¤šé€‰" in cat: return "Xå‹é¢˜"
    if "å•é€‰" in cat: return "å•é€‰é¢˜"
    if "åˆ¤æ–­" in cat: return "åˆ¤æ–­é¢˜"
    if "å¡«ç©º" in cat: return "å¡«ç©ºé¢˜"
    if "ç®€ç­”" in cat: return "ç®€ç­”é¢˜"
    if "è®¡ç®—" in cat: return "è®¡ç®—é¢˜"
    if "ç¼–ç¨‹" in cat: return "ç¼–ç¨‹é¢˜"
    if "ç—…ä¾‹" in cat: return "ç—…ä¾‹åˆ†æé¢˜"
    return cat if cat.endswith("é¢˜") else cat + "é¢˜"


def repair_json(jstr):
    jstr = jstr.strip()
    if "```json" in jstr:
        jstr = jstr.split("```json")[1].split("```")[0]
    elif "```" in jstr:
        jstr = jstr.split("```")[1].split("```")[0]
    jstr = jstr.strip()
    if not jstr.endswith("]"):
        idx = jstr.rfind("}")
        if idx != -1:
            jstr = jstr[:idx + 1] + "]"
        else:
            return "[]"
    return jstr


def extract_global_answers(txt):
    print("   ğŸ” æ‰«æå‚è€ƒç­”æ¡ˆ...")
    try:
        res = client.chat.completions.create(
            model=AI_MODEL_NAME, messages=[{"role": "user", "content": "æå–å‚è€ƒç­”æ¡ˆï¼Œçº¯æ–‡æœ¬åˆ—è¡¨ã€‚\n\n" + txt[:100000]}],
            temperature=0.1, timeout=120
        )
        return res.choices[0].message.content
    except:
        return ""


def process_chunk(args):
    chunk, idx, ans_key = args
    prompt = f"""
        [ç³»ç»Ÿè§’è‰²è®¾å®š]
        ä½ æ˜¯ç”± Python è„šæœ¬è°ƒç”¨çš„â€œå…¨å­¦ç§‘è¯•é¢˜æ•°æ®ç»“æ„åŒ–å¼•æ“â€ã€‚
        **ä½ ä¸æ˜¯èŠå¤©åŠ©æ‰‹ï¼Œä¸¥ç¦è¾“å‡ºä»»ä½•å¯’æš„è¯­ã€è§£é‡Šæ€§æ–‡å­—æˆ– Markdown ä»£ç æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚**
        ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯å°†è¾“å…¥çš„éç»“æ„åŒ–æ–‡æœ¬åˆ‡ç‰‡ï¼Œç²¾å‡†è§£æä¸ºç¬¦åˆ Schema å®šä¹‰çš„ JSON æ•°ç»„ã€‚

        [å½“å‰å¤„ç†å­¦ç§‘]
        - å­¦ç§‘åç§°ï¼š**{SUBJECT}**
        - å­¦ç§‘èƒŒæ™¯ï¼š{DESC}
        ï¼ˆè¯·åˆ©ç”¨å­¦ç§‘èƒŒæ™¯çŸ¥è¯†æ¥è¾…åŠ©åˆ¤æ–­é¢˜å‹ï¼Œä¾‹å¦‚ï¼šåŒ»å­¦å¸¸å‡ºç° A1/ç—…ä¾‹åˆ†æï¼›è®¡ç®—æœºå¸¸å‡ºç°ç¼–ç¨‹/ç®—æ³•ï¼›æ•°å­¦å¸¸å‡ºç°è¯æ˜/è®¡ç®—ï¼‰

        [å…¨å±€ä¸Šä¸‹æ–‡ï¼šå‚è€ƒç­”æ¡ˆåº“]
        ---------------------------------------------------------------------
        {ans_key[:5000]} ... (è‹¥è¿‡é•¿å·²è‡ªåŠ¨æˆªæ–­ï¼Œä»…ä¾›æŸ¥é˜…)
        ---------------------------------------------------------------------

        [ä¸¥æ ¼æ‰§è¡Œå®ˆåˆ™ (Chain of Constraints)]

        1. **è¾¹ç•Œæˆªæ–­å¤„ç† (æœ€é«˜ä¼˜å…ˆçº§)**ï¼š
           - è¾“å…¥æ–‡æœ¬æ˜¯é•¿æ–‡æ¡£çš„ä¸€ä¸ªåˆ‡ç‰‡ã€‚
           - **ç›´æ¥ä¸¢å¼ƒ**åˆ‡ç‰‡å¼€å¤´å¤„ä¸å®Œæ•´çš„æ®‹ç¼ºæ®µè½ï¼ˆä¾‹å¦‚ï¼šåªæœ‰é€‰é¡¹æ²¡æœ‰é¢˜å¹²ï¼‰ã€‚
           - **ç›´æ¥ä¸¢å¼ƒ**åˆ‡ç‰‡æœ«å°¾å¤„ä¸å®Œæ•´çš„æ®‹ç¼ºæ®µè½ï¼ˆä¾‹å¦‚ï¼šåªæœ‰é¢˜å¹²æ²¡æœ‰é€‰é¡¹ï¼‰ã€‚
           - åªæå–ä¸­é—´è¯­ä¹‰å®Œæ•´çš„é¢˜ç›®ã€‚

        2. **ç­”æ¡ˆåŒ¹é…é€»è¾‘ (ä¸‰çº§ç€‘å¸ƒæµ)**ï¼š
           - **Level 1 (è‡ªå¸¦)**ï¼šä¼˜å…ˆæå–é¢˜ç›®æ–‡æœ¬å†…éƒ¨è‡ªå¸¦çš„ç­”æ¡ˆï¼ˆä¾‹å¦‚ï¼šæ‹¬å·å†…çš„å­—æ¯ã€é¢˜å¹²æœ«å°¾çš„ç­”æ¡ˆã€é€‰é¡¹ä¸‹æ–¹çš„â€œã€ç­”æ¡ˆã€‘â€ï¼‰ã€‚
           - **Level 2 (æŸ¥è¡¨)**ï¼šæå–é¢˜ç›®ä¸­çš„ã€é¢˜å·ã€‘ï¼ˆå¦‚ "53."ï¼‰ï¼Œå»ä¸Šæ–¹çš„ [å‚è€ƒç­”æ¡ˆåº“] ä¸­æŸ¥æ‰¾å¯¹åº”é¢˜å·çš„ç­”æ¡ˆã€‚
           - **Level 3 (ç•™ç©º)**ï¼šå¦‚æœ Level 1 å’Œ Level 2 éƒ½å¤±è´¥ï¼Œ`answer` å­—æ®µå¿…é¡»ç•™ç©ºå­—ç¬¦ä¸² ""ã€‚**ä¸¥ç¦æ ¹æ®é¢˜ç›®å†…å®¹è‡ªå·±åšé¢˜ï¼ä¸¥ç¦éšæœºç”Ÿæˆï¼**

        3. **æ–‡æœ¬æ¸…æ´—è§„åˆ™**ï¼š
           - **Content æ¸…æ´—**ï¼šç§»é™¤é¢˜å¹²å¼€å¤´çš„é¢˜å·ï¼ˆä¾‹å¦‚ï¼š"1. ä¸‹åˆ—å“ªé¡¹..." -> "ä¸‹åˆ—å“ªé¡¹..."ï¼‰ã€‚
           - **Option æ¸…æ´—**ï¼šç§»é™¤é€‰é¡¹å¼€å¤´çš„æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼š"A. é˜¿å¸åŒ¹æ—" -> label:"A", text:"é˜¿å¸åŒ¹æ—"ï¼‰ã€‚
           - **ç‰¹æ®Šç¬¦å·**ï¼šä¿ç•™ä»£ç å—ã€æ•°å­¦å…¬å¼ï¼ˆLaTeXï¼‰ã€åŒ–å­¦å¼åŸæœ¬çš„æ ¼å¼ï¼Œä¸è¦éšæ„è½¬ä¹‰ã€‚

        4. **é¢˜å‹å½’ä¸€åŒ–æ˜ å°„ (Category Mapping)**ï¼š
           - **åŒ»å­¦ä¸“ç”¨**ï¼š
             * 5ä¸ªé€‰é¡¹(A-E)å•é€‰ -> "A1å‹é¢˜" æˆ– "A2å‹é¢˜"
             * å…±ç”¨é¢˜å¹²/é…ä¼ -> "B1å‹é¢˜"
             * å¤šé€‰é¢˜ -> "Xå‹é¢˜"
             * ç—…ä¾‹æè¿°/è¯Šæ–­ -> "ç—…ä¾‹åˆ†æé¢˜"
           - **ç†å·¥/è®¡ç®—æœºä¸“ç”¨**ï¼š
             * ä»£ç è¡¥å…¨/ç®—æ³•å®ç° -> "ç¼–ç¨‹é¢˜"
             * æ•°å€¼è®¡ç®—/å…¬å¼æ¨å¯¼ -> "è®¡ç®—é¢˜"
             * é€»è¾‘è¯æ˜ -> "è¯æ˜é¢˜"
             * ç³»ç»Ÿè®¾è®¡/åº”ç”¨åœºæ™¯ -> "åº”ç”¨é¢˜"
           - **é€šç”¨åŸºç¡€**ï¼š
             * 4ä¸ªé€‰é¡¹å•é€‰ -> "å•é€‰é¢˜"
             * å¤šä¸ªæ­£ç¡®ç­”æ¡ˆ/ä¸å®šé¡¹ -> "å¤šé€‰é¢˜"
             * å¯¹/é”™, T/F -> "åˆ¤æ–­é¢˜"
             * ä¸‹åˆ’çº¿/æ‹¬å·å¡«ç©º -> "å¡«ç©ºé¢˜"
             * æ— é€‰é¡¹ä¸»è§‚é—®ç­” -> "ç®€ç­”é¢˜"
             * åè¯è§£é‡Š -> "åè¯è§£é‡Šé¢˜"

        [è¾“å‡ºæ ¼å¼è§„èŒƒ (JSON Schema)]
        å¿…é¡»è¿”å›ä¸€ä¸ªçº¯å‡€çš„ JSON Arrayï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        [
          {{
            "category": "String (å¿…é¡»æ˜¯ä¸Šè¿°æ˜ å°„è¡¨ä¸­çš„æ ‡å‡†åç§°)",
            "type": "Enum (SINGLE_CHOICE / MULTI_CHOICE / TRUE_FALSE / FILL_BLANK / ESSAY)",
            "content": "String (æ¸…æ´—åçš„å®Œæ•´é¢˜å¹²)",
            "options": [
               {{"label": "A", "text": "é€‰é¡¹å†…å®¹..."}},
               {{"label": "B", "text": "é€‰é¡¹å†…å®¹..."}}
            ],
            "answer": "String (ä¾‹å¦‚ 'A', 'ABC', 'True', 'void main()...')",
            "analysis": "String (å¦‚æœæ–‡æœ¬ä¸­æœ‰è§£æåˆ™æå–ï¼Œå¦åˆ™ç•™ç©º)"
          }}
        ]

        [å¾…å¤„ç†æ–‡æœ¬åˆ‡ç‰‡]
        {chunk}
        """

    last_err = ""
    for i in range(MAX_RETRIES):
        try:
            res = client.chat.completions.create(
                model=AI_MODEL_NAME, messages=[{"role": "user", "content": prompt}],
                temperature=0.1, top_p=0.7, max_tokens=4000, timeout=API_TIMEOUT
            )
            content = repair_json(res.choices[0].message.content)
            try:
                data = json.loads(content)
                if isinstance(data, list): return data, None
                if isinstance(data, dict): return [data], None
                return [], f"Chunk {idx + 1}: JSONæ ¼å¼å¼‚å¸¸"
            except:
                continue
        except Exception as e:
            last_err = str(e)
            time.sleep((2 ** i) + random.random())

    return [], f"Chunk {idx + 1} å¤±è´¥ (API: {last_err})"


def main():
    st = time.time()
    if not os.path.exists(INPUT_DIR): return
    files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]
    if not files: return

    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    exist_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith("output") and f.endswith(".json")]
    next_idx = 1
    for f in exist_files:
        m = re.search(r'output(\d+)', f)
        if m: next_idx = max(next_idx, int(m.group(1)) + 1)
    target_file = os.path.join(OUTPUT_DIR, f"output{next_idx}.json")

    print(f"ğŸš€ [{SUBJECT}] å¯åŠ¨ | åˆ†æ”¯: {GITHUB_REF_NAME}")

    all_qs = []
    stats = {"file_count": len(files), "total_chunks": 0, "success_chunks": 0, "failed_chunks": 0, "errors": []}

    for fname in files:
        print(f"\nğŸ“„ {fname}")
        txt = read_docx(os.path.join(INPUT_DIR, fname))
        if not txt: continue

        ans = extract_global_answers(txt)
        chunks = get_chunks(txt, CHUNK_SIZE, OVERLAP)
        stats['total_chunks'] += len(chunks)

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exc:
            futures = [exc.submit(process_chunk, (c, i, ans)) for i, c in enumerate(chunks)]
            for fut in tqdm(as_completed(futures), total=len(chunks)):
                qs, err = fut.result()
                if err:
                    stats['failed_chunks'] += 1
                    stats['errors'].append(err)
                    print(f"   âŒ {err}")
                else:
                    stats['success_chunks'] += 1
                    if qs:
                        for q in qs:
                            q['id'] = str(uuid.uuid4())
                            q['number'] = len(all_qs) + 1
                            q['chapter'] = fname.replace(".docx", "")
                            q['category'] = normalize_category(q.get('category', 'ç»¼åˆé¢˜'))
                            if 'analysis' not in q: q['analysis'] = ""
                            all_qs.append(q)

    final = {"version": "V7-Report", "subject": SUBJECT, "data": all_qs}
    with open(target_file, 'w', encoding='utf-8') as f:
        json.dump(final, f, ensure_ascii=False, indent=2)
    with open("last_generated_file.txt", "w") as f:
        f.write(target_file)

    stats['duration'] = time.time() - st
    stats['total_questions'] = len(all_qs)
    print(f"\nâœ¨ å®Œæˆï¼æå– {len(all_qs)} é¢˜")
    send_report(stats)


if __name__ == "__main__": main()