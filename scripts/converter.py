import json
import os
import uuid
import hashlib
import time
import requests
import random
import re
from docx import Document
from zhipuai import ZhipuAI
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ================= ðŸ›¡ï¸ æ™ºèƒ½é…ç½®åŠ è½½æ¨¡å— =================
CONFIG_FILE = "config.json"


def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


APP_CONFIG = load_config()
SUBJECT = APP_CONFIG.get("subject_name", "é€šç”¨å­¦ç§‘")
DESC = APP_CONFIG.get("description", "")
KEY_INDEX = APP_CONFIG.get("key_index", 0)  # ã€æ ¸å¿ƒã€‘èŽ·å–ç´¢å¼•ï¼Œé»˜è®¤ç”¨ç¬¬ä¸€ä¸ª

INPUT_DIR = "input"
OUTPUT_DIR = "output"
MAX_WORKERS = APP_CONFIG.get("max_workers", 16)

# ================= ðŸ”‘ å¯†é’¥æ± è§£æžé€»è¾‘ =================
# è¯»å–çŽ¯å¢ƒå˜é‡é‡Œçš„æ•´ä¸ªå­—ç¬¦ä¸²
KEY_POOL_STR = os.getenv("ZHIPU_KEY_POOL", "")
PUSHPLUS_TOKEN = os.getenv("PUSHPLUS_TOKEN")


def get_api_key():
    """æ ¹æ® Config é‡Œçš„ index ä»ŽçŽ¯å¢ƒå˜é‡æ± ä¸­æå– Key"""
    if not KEY_POOL_STR:
        print("âŒ é”™è¯¯ï¼šçŽ¯å¢ƒå˜é‡ ZHIPU_KEY_POOL æœªè®¾ç½®æˆ–ä¸ºç©ºï¼")
        return None

    # æŒ‰é€—å·åˆ‡å‰²
    keys = [k.strip() for k in KEY_POOL_STR.split(',') if k.strip()]

    if not keys:
        print("âŒ é”™è¯¯ï¼šå¯†é’¥æ± ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ Keyï¼")
        return None

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦è¶Šç•Œ
    if KEY_INDEX >= len(keys):
        print(f"âš ï¸ è­¦å‘Šï¼šconfig.json è¯·æ±‚ç¬¬ {KEY_INDEX} ä¸ª Keyï¼Œä½†æ± å­é‡Œåªæœ‰ {len(keys)} ä¸ªã€‚")
        print(f"ðŸ”„ è‡ªåŠ¨å›žæ»šä½¿ç”¨ç¬¬ 1 ä¸ª Keyã€‚")
        return keys[0]

    print(f"ðŸ”‘ å·²ä»Žæ± ä¸­é€‰ä¸­ç¬¬ {KEY_INDEX} ä¸ª Key (Index {KEY_INDEX}) è¿›è¡Œå·¥ä½œã€‚")
    return keys[KEY_INDEX]


# èŽ·å–æœ€ç»ˆçš„ Key
ZHIPU_API_KEY = get_api_key()

AI_MODEL_NAME = "glm-4-flash"
CHUNK_SIZE = 2000
OVERLAP = 200
MAX_RETRIES = 5
API_TIMEOUT = 120
# =======================================================

if not ZHIPU_API_KEY:
    print("âŒ ä¸¥é‡é”™è¯¯ï¼šæ— æ³•èŽ·å–æœ‰æ•ˆçš„ ZHIPU_API_KEYï¼Œè„šæœ¬ç»ˆæ­¢ã€‚")
    exit(1)

client = ZhipuAI(api_key=ZHIPU_API_KEY)

STANDARD_CATEGORIES = {
    "A1åž‹é¢˜", "A2åž‹é¢˜", "B1åž‹é¢˜", "Xåž‹é¢˜", "é…ä¼é¢˜", "ç—…ä¾‹åˆ†æžé¢˜",
    "å•é€‰é¢˜", "å¤šé€‰é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜",
    "åè¯è§£é‡Šé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜",
    "è®¡ç®—é¢˜", "è¯æ˜Žé¢˜", "ç¼–ç¨‹é¢˜", "åº”ç”¨é¢˜", "ç»¼åˆé¢˜"
}


def get_next_output_filename():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    existing_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith("output") and f.endswith(".json")]
    max_index = 0
    for f in existing_files:
        match = re.search(r'output(\d+)\.json', f)
        if match:
            idx = int(match.group(1))
            if idx > max_index:
                max_index = idx
    return os.path.join(OUTPUT_DIR, f"output{max_index + 1}.json")


def send_notification(title, content):
    if not PUSHPLUS_TOKEN: return
    try:
        requests.post("http://www.pushplus.plus/send", json={
            "token": PUSHPLUS_TOKEN, "title": title, "content": content, "template": "html"
        }, timeout=5)
    except:
        pass


def read_docx(file_path):
    if not os.path.exists(file_path): return ""
    try:
        doc = Document(file_path)
        return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
    except:
        return ""


def get_chunks(text, chunk_size, overlap):
    chunks = []
    start = 0
    total_len = len(text)
    while start < total_len:
        end = min(start + chunk_size, total_len)
        chunks.append(text[start:end])
        if end == total_len: break
        start = end - overlap
    return chunks


def normalize_category(raw_cat):
    if not raw_cat: return "ç»¼åˆé¢˜"
    cat = raw_cat.strip()
    # åŒ»å­¦
    if "A1" in cat: return "A1åž‹é¢˜"
    if "A2" in cat: return "A2åž‹é¢˜"
    if "B1" in cat or "é…ä¼" in cat: return "B1åž‹é¢˜"
    if "Xåž‹" in cat: return "Xåž‹é¢˜"
    if "ç—…ä¾‹" in cat or "ç—…æ¡ˆ" in cat: return "ç—…ä¾‹åˆ†æžé¢˜"
    # é€šç”¨
    if "å¤šé€‰" in cat or "ä¸å®šé¡¹" in cat: return "å¤šé€‰é¢˜"
    if "å•é€‰" in cat: return "å•é€‰é¢˜"
    if "åˆ¤æ–­" in cat or "æ˜¯éž" in cat: return "åˆ¤æ–­é¢˜"
    if "å¡«ç©º" in cat: return "å¡«ç©ºé¢˜"
    if "åè¯" in cat: return "åè¯è§£é‡Šé¢˜"
    if "ç®€ç­”" in cat or "é—®ç­”" in cat: return "ç®€ç­”é¢˜"
    if "è®ºè¿°" in cat: return "è®ºè¿°é¢˜"
    # ç†å·¥
    if "è®¡ç®—" in cat: return "è®¡ç®—é¢˜"
    if "è¯æ˜Ž" in cat: return "è¯æ˜Žé¢˜"
    if "ç¼–ç¨‹" in cat or "ä»£ç " in cat: return "ç¼–ç¨‹é¢˜"
    if "åº”ç”¨" in cat or "è®¾è®¡" in cat: return "åº”ç”¨é¢˜"

    if cat in STANDARD_CATEGORIES: return cat
    if not cat.endswith("é¢˜"): return cat + "é¢˜"
    return cat


def repair_json(json_str):
    json_str = json_str.strip()
    if "```json" in json_str:
        json_str = json_str.split("```json")[1].split("```")[0]
    elif "```" in json_str:
        json_str = json_str.split("```")[1].split("```")[0]
    json_str = json_str.strip()
    if not json_str.endswith("]"):
        last_brace = json_str.rfind("}")
        if last_brace != -1:
            json_str = json_str[:last_brace + 1] + "]"
        else:
            return "[]"
    return json_str


def extract_global_answers(full_text):
    print("   ðŸ” [Step 1] æ‰«ææ–‡æ¡£å‚è€ƒç­”æ¡ˆ...")
    safe_text = full_text[:100000]
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ†æžå¸ˆã€‚è¯·æå–æ–‡æ¡£ä¸­çš„â€œå‚è€ƒç­”æ¡ˆâ€ã€‚
    è¦æ±‚ï¼šåªæå–ç­”æ¡ˆæ–‡æœ¬ï¼ˆå¦‚ 1.A 2.Bï¼‰ï¼Œçº¯æ–‡æœ¬åˆ—è¡¨ã€‚å¦‚æžœä¸é›†ä¸­ï¼Œè¿”å›žâ€œæ— â€ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=AI_MODEL_NAME,
            messages=[{"role": "user", "content": prompt + "\n\n" + safe_text}],
            temperature=0.1,
            timeout=120
        )
        return response.choices[0].message.content
    except:
        return ""


def process_single_chunk(args):
    chunk, index, total, answer_key = args

    prompt = f"""
    [ç³»ç»Ÿè§’è‰²]
    ä½ æ˜¯ä¸€ä½**{SUBJECT}**é¢†åŸŸçš„è¯•é¢˜æ•°æ®æ¸…æ´—ä¸“å®¶ã€‚
    èƒŒæ™¯ï¼š{DESC}
    ä»»åŠ¡ï¼šå°†éžç»“æž„åŒ–æ–‡æœ¬è½¬æ¢ä¸ºç¬¦åˆ Schema çš„ JSON æ•°ç»„ã€‚

    [è¾“å…¥ä¸Šä¸‹æ–‡ï¼šå‚è€ƒç­”æ¡ˆåº“]
    {answer_key[:5000]}

    [æ ¸å¿ƒå¤„ç†å®ˆåˆ™]
    1. **è¾¹ç•Œä¸¢å¼ƒ**ï¼šåˆ‡ç‰‡é¦–å°¾æ®‹ç¼ºå¥å­ç›´æŽ¥ä¸¢å¼ƒã€‚
    2. **ç­”æ¡ˆåŒ¹é…**ï¼š
       - ä¼˜å…ˆæå–è‡ªå¸¦ç­”æ¡ˆã€‚
       - å…¶æ¬¡æŸ¥å‚è€ƒç­”æ¡ˆåº“ã€‚
       - æ‰¾ä¸åˆ°ç•™ç©º ""ã€‚ä¸¥ç¦çžŽçŒœã€‚
    3. **å­¦ç§‘å½’ç±»**ï¼š
       - åŒ»å­¦ï¼šA1/A2/B1/ç—…ä¾‹åˆ†æžã€‚
       - ç†å·¥ï¼šç¼–ç¨‹/è®¡ç®—/è¯æ˜Ž/åº”ç”¨ã€‚
       - é€šç”¨ï¼šå•é€‰/å¤šé€‰/å¡«ç©º/åˆ¤æ–­ã€‚

    [JSON è¾“å‡ºç»“æž„]
    Strict JSON Array.
    [
      {{
        "category": "String (è§æ˜ å°„è¡¨)",
        "type": "Enum (SINGLE_CHOICE / MULTI_CHOICE / TRUE_FALSE / FILL_BLANK / ESSAY)",
        "content": "String (é¢˜å¹²)",
        "options": [
           {{"label": "A", "text": "..."}}
        ],
        "answer": "String",
        "analysis": ""
      }}
    ]

    [å¾…å¤„ç†æ–‡æœ¬]
    {chunk}
    """

    for attempt in range(MAX_RETRIES):
        try:
            temp = 0.0 if attempt < 2 else 0.1
            response = client.chat.completions.create(
                model=AI_MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                top_p=0.7,
                max_tokens=4000,
                timeout=API_TIMEOUT
            )
            content = response.choices[0].message.content
            content = repair_json(content)

            try:
                res = json.loads(content)
                if isinstance(res, list): return res
                if isinstance(res, dict): return [res]
                return []
            except json.JSONDecodeError:
                continue

        except Exception:
            wait_time = (2 ** attempt) + random.uniform(0, 1)
            time.sleep(wait_time)

    return []


def main():
    start_time = time.time()

    if not os.path.exists(INPUT_DIR): os.makedirs(INPUT_DIR)
    docx_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]

    if not docx_files:
        print("âŒ input ç›®å½•ä¸ºç©ºã€‚")
        return

    target_output_file = get_next_output_filename()
    print(f"ðŸš€ [{SUBJECT}] å…¨é€Ÿå·¥åŽ‚å¯åŠ¨ | ç›®æ ‡: {target_output_file} | çº¿ç¨‹: {MAX_WORKERS}")

    all_questions = []

    for filename in docx_files:
        print(f"\nðŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
        raw_text = read_docx(os.path.join(INPUT_DIR, filename))
        if not raw_text: continue

        global_answers = extract_global_answers(raw_text)
        chunks = get_chunks(raw_text, CHUNK_SIZE, OVERLAP)

        tasks_args = [(chunk, i, len(chunks), global_answers) for i, chunk in enumerate(chunks)]
        chunk_added = 0

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # å…¨é€Ÿæ¨¡å¼ï¼šä¸åŠ  sleep å»¶è¿Ÿ
            results = list(tqdm(executor.map(process_single_chunk, tasks_args), total=len(chunks), unit="åˆ‡ç‰‡"))

            for items in results:
                if items:
                    for item in items:
                        item['id'] = str(uuid.uuid4())
                        item['number'] = len(all_questions) + 1
                        item['chapter'] = filename.replace(".docx", "")
                        item['category'] = normalize_category(item.get('category', 'ç»¼åˆé¢˜'))
                        if 'analysis' not in item: item['analysis'] = ""
                        all_questions.append(item)
                        chunk_added += 1

        print(f"   âœ… æœ¬æ–‡ä»¶æå–: {chunk_added} é“")

    final_json = {
        "version": "FullSpeed-V5",
        "subject": SUBJECT,
        "source": "GLM-4-Flash",
        "total_count": len(all_questions),
        "data": all_questions
    }

    with open(target_output_file, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)

    duration = time.time() - start_time
    msg = f"[{SUBJECT}] è½¬æ¢å®Œæˆï¼\nè€—æ—¶: {duration:.1f}s\næ–‡ä»¶: {target_output_file}\né¢˜æ•°: {len(all_questions)}"
    print(f"\nâœ¨ {msg}")

    with open("last_generated_file.txt", "w") as f:
        f.write(target_output_file)


if __name__ == "__main__":
    main()