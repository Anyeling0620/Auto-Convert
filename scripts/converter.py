import json
import os
import uuid
import hashlib
import time
import requests
import random
import re
from docx import Document
from zhipuai import ZhipuAI
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ================= üõ°Ô∏è Á®≥ÂÅ•Ê®°ÂºèÈÖçÁΩÆ =================
INPUT_DIR = "input"
OUTPUT_DIR = "output"

ZHIPU_API_KEY = os.getenv("ZHIPU_API_KEY")
PUSHPLUS_TOKEN = os.getenv("PUSHPLUS_TOKEN")

AI_MODEL_NAME = "glm-4-flash"

# „ÄêÊ†∏ÂøÉ‰ºòÂåñÈÖçÁΩÆ„Äë
MAX_WORKERS = 5  # ÈôçÁ∫ßÔºö‰ªé 16 Èôç‰∏∫ 5ÔºåÈÅøÂÖçÊã•Â†µ
CHUNK_SIZE = 2000
OVERLAP = 200
MAX_RETRIES = 5
API_TIMEOUT = 60  # Âº∫Âà∂Ë∂ÖÊó∂Ôºö60Áßí‰∏çÂõûËØùÂ∞±ÈáçËØïÔºåÂà´Á≠â20ÂàÜÈíü
REQUEST_INTERVAL = 1.0  # ËäÇÊµÅÈòÄÔºöÊØèÁßíÂè™Âèë‰∏Ä‰∏™ËØ∑Ê±ÇÔºåÂπ≥ÊªëÊµÅÈáè
# =================================================

if not ZHIPU_API_KEY:
    print("‚ùå ‰∏•ÈáçÈîôËØØÔºöÊú™ÊâæÂà∞ ZHIPU_API_KEY")
    exit(1)

client = ZhipuAI(api_key=ZHIPU_API_KEY)

STANDARD_CATEGORIES = {
    "A1ÂûãÈ¢ò", "A2ÂûãÈ¢ò", "B1ÂûãÈ¢ò", "XÂûãÈ¢ò", "ÈÖç‰ºçÈ¢ò", "ÁóÖ‰æãÂàÜÊûêÈ¢ò",
    "ÂçïÈÄâÈ¢ò", "Â§öÈÄâÈ¢ò", "Âà§Êñ≠È¢ò", "Â°´Á©∫È¢ò",
    "ÂêçËØçËß£ÈáäÈ¢ò", "ÁÆÄÁ≠îÈ¢ò", "ËÆ∫Ëø∞È¢ò",
    "ËÆ°ÁÆóÈ¢ò", "ËØÅÊòéÈ¢ò", "ÁºñÁ®ãÈ¢ò", "Â∫îÁî®È¢ò", "ÁªºÂêàÈ¢ò"
}


def get_next_output_filename():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    existing_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith("output") and f.endswith(".json")]
    max_index = 0
    for f in existing_files:
        match = re.search(r'output(\d+)\.json', f)
        if match:
            idx = int(match.group(1))
            if idx > max_index:
                max_index = idx
    return os.path.join(OUTPUT_DIR, f"output{max_index + 1}.json")


def send_notification(title, content):
    if not PUSHPLUS_TOKEN: return
    try:
        requests.post("http://www.pushplus.plus/send", json={
            "token": PUSHPLUS_TOKEN, "title": title, "content": content, "template": "html"
        }, timeout=5)
    except:
        pass


def read_docx(file_path):
    if not os.path.exists(file_path): return ""
    try:
        doc = Document(file_path)
        return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
    except Exception as e:
        print(f"‚ùå ËØªÂèñÊñá‰ª∂Â§±Ë¥•: {e}")
        return ""


def get_chunks(text, chunk_size, overlap):
    chunks = []
    start = 0
    total_len = len(text)
    while start < total_len:
        end = min(start + chunk_size, total_len)
        chunks.append(text[start:end])
        if end == total_len: break
        start = end - overlap
    return chunks


def normalize_category(raw_cat):
    if not raw_cat: return "ÁªºÂêàÈ¢ò"
    cat = raw_cat.strip()

    if "A1" in cat: return "A1ÂûãÈ¢ò"
    if "A2" in cat: return "A2ÂûãÈ¢ò"
    if "B1" in cat or "ÈÖç‰ºç" in cat: return "B1ÂûãÈ¢ò"
    if "XÂûã" in cat: return "XÂûãÈ¢ò"
    if "ÁóÖ‰æã" in cat or "ÁóÖÊ°à" in cat: return "ÁóÖ‰æãÂàÜÊûêÈ¢ò"

    if "Â§öÈÄâ" in cat or "‰∏çÂÆöÈ°π" in cat: return "Â§öÈÄâÈ¢ò"
    if "ÂçïÈÄâ" in cat: return "ÂçïÈÄâÈ¢ò"
    if "Âà§Êñ≠" in cat or "ÊòØÈùû" in cat: return "Âà§Êñ≠È¢ò"
    if "Â°´Á©∫" in cat: return "Â°´Á©∫È¢ò"
    if "ÂêçËØç" in cat: return "ÂêçËØçËß£ÈáäÈ¢ò"
    if "ÁÆÄÁ≠î" in cat or "ÈóÆÁ≠î" in cat: return "ÁÆÄÁ≠îÈ¢ò"
    if "ËÆ∫Ëø∞" in cat: return "ËÆ∫Ëø∞È¢ò"
    if "ËÆ°ÁÆó" in cat: return "ËÆ°ÁÆóÈ¢ò"
    if "ËØÅÊòé" in cat: return "ËØÅÊòéÈ¢ò"
    if "ÁºñÁ®ã" in cat or "‰ª£Á†Å" in cat: return "ÁºñÁ®ãÈ¢ò"
    if "Â∫îÁî®" in cat: return "Â∫îÁî®È¢ò"

    if cat in STANDARD_CATEGORIES: return cat
    if not cat.endswith("È¢ò"): return cat + "È¢ò"
    return cat


def repair_json(json_str):
    json_str = json_str.strip()
    if "```json" in json_str:
        json_str = json_str.split("```json")[1].split("```")[0]
    elif "```" in json_str:
        json_str = json_str.split("```")[1].split("```")[0]
    json_str = json_str.strip()

    # Â∞ùËØïËá™Âä®Èó≠Âêà
    if not json_str.endswith("]"):
        last_brace = json_str.rfind("}")
        if last_brace != -1:
            json_str = json_str[:last_brace + 1] + "]"
        else:
            return "[]"  # Êó†Ê≥ï‰øÆÂ§ç
    return json_str


def extract_global_answers(full_text):
    print("   üîç [Step 1] Êâ´ÊèèÊñáÊ°£ÂèÇËÄÉÁ≠îÊ°à...")
    safe_text = full_text[:100000]
    prompt = """
    ‰Ω†ÊòØ‰∏Ä‰∏™ÊñáÊ°£ÂàÜÊûêÂ∏à„ÄÇËØ∑ÊèêÂèñÊñáÊ°£‰∏≠ÁöÑ‚ÄúÂèÇËÄÉÁ≠îÊ°à‚ÄùÈÉ®ÂàÜ„ÄÇ
    „ÄêË¶ÅÊ±Ç„Äë
    1. ÂøΩÁï•È¢òÁõÆÂÜÖÂÆπÔºå**Âè™ÊèêÂèñÁ≠îÊ°à**„ÄÇ
    2. ËæìÂá∫Ê†ºÂºè‰∏∫Á∫ØÊñáÊú¨ÂàóË°®ÔºàÂ¶ÇÔºö1.A 2.B 3.C ...Ôºâ„ÄÇ
    3. Â¶ÇÊûúÊâæ‰∏çÂà∞ÈõÜ‰∏≠Á≠îÊ°àÔºåËøîÂõû‚ÄúÊó†‚Äù„ÄÇ
    """
    try:
        response = client.chat.completions.create(
            model=AI_MODEL_NAME,
            messages=[{"role": "user", "content": prompt + "\n\n" + safe_text}],
            temperature=0.1,
            timeout=120
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"   ‚ö†Ô∏è Á≠îÊ°àÊâ´ÊèèÂ§±Ë¥•: {e}")
        return ""


def process_single_chunk(args):
    chunk, index, total, answer_key = args

    # =================================================================
    # ‚ö° ‰∏•Ë∞®Á∫ß Prompt (‰∏≠ÊñáÁâà)
    # =================================================================
    prompt = f"""
    [Á≥ªÁªüËßíËâ≤]
    ‰Ω†ÊòØ‰∏Ä‰∏™‰∏•Ê†ºÈÅµÂæ™Êåá‰ª§ÁöÑ‚ÄúÈÄöÁî®ËØïÈ¢òÊï∞ÊçÆÊ∏ÖÊ¥óÂºïÊìé‚Äù„ÄÇ‰Ω†**‰∏çÊòØ**ËÅäÂ§©Êú∫Âô®‰∫∫„ÄÇ
    ‰Ω†ÁöÑ‰ªªÂä°ÊòØÂ∞ÜÈùûÁªìÊûÑÂåñÊñáÊú¨ËΩ¨Êç¢‰∏∫Á¨¶Âêà Schema ÁöÑ JSON Êï∞ÁªÑ„ÄÇ

    [ËæìÂÖ•‰∏ä‰∏ãÊñáÔºöÂèÇËÄÉÁ≠îÊ°àÂ∫ì]
    -----------------------------------
    {answer_key[:5000]}
    -----------------------------------

    [Ê†∏ÂøÉÂ§ÑÁêÜÂÆàÂàô]
    1. **ËæπÁïå‰∏¢ÂºÉÂéüÂàô**ÔºöËæìÂÖ•ÊñáÊú¨ÊòØ‰∏Ä‰∏™ÂàáÁâá„ÄÇÂ¶ÇÊûúÂàáÁâáÂºÄÂ§¥ÁöÑÁ¨¨‰∏ÄÂè•ËØùÊòØ‰∏çÂÆåÊï¥ÁöÑÔºåÊàñËÄÖÂàáÁâáÊú´Â∞æÊúÄÂêé‰∏ÄÂè•ËØù‰∏çÂÆåÊï¥Ôºå**ÂøÖÈ°ªÁõ¥Êé•‰∏¢ÂºÉ**„ÄÇ
    2. **Á≠îÊ°àÂåπÈÖç‰ºòÂÖàÁ∫ß**Ôºö
       - ‰ºòÂÖàÔºöÈ¢òÁõÆÊñáÊú¨‰∏≠Ëá™Â∏¶ÁöÑÁ≠îÊ°à„ÄÇ
       - ÂÖ∂Ê¨°ÔºöÊ†πÊçÆ„ÄêÈ¢òÂè∑„ÄëÂéªÂèÇËÄÉÁ≠îÊ°àÂ∫ìÊü•Êâæ„ÄÇ
       - ÊúÄÂêéÔºöÂ¶ÇÊûúÈÉΩÊâæ‰∏çÂà∞Ôºå`answer` Â≠óÊÆµÁïôÁ©∫ ""„ÄÇ**‰∏•Á¶ÅÈöèÊú∫ÁîüÊàêÁ≠îÊ°à„ÄÇ**
    3. **ÂÜÖÂÆπÊ∏ÖÊ¥ó**Ôºö
       - ÁßªÈô§È¢òÂπ≤ÂºÄÂ§¥ÁöÑÈ¢òÂè∑„ÄÇ
       - ÁßªÈô§ÈÄâÈ°πÂºÄÂ§¥ÁöÑÊ†áÁ≠æ A. B. Á≠â„ÄÇ

    [JSON ËæìÂá∫ÁªìÊûÑ (Strict Schema)]
    ÂøÖÈ°ªËøîÂõû‰∏Ä‰∏™ JSON Êï∞ÁªÑ„ÄÇ
    [
      {{
        "category": "String (Â¶Ç A1ÂûãÈ¢ò, ÂçïÈÄâÈ¢ò, Â°´Á©∫È¢ò...)",
        "type": "Enum (SINGLE_CHOICE / MULTI_CHOICE / TRUE_FALSE / FILL_BLANK / ESSAY)",
        "content": "String (Ê∏ÖÊ¥óÂêéÁöÑÈ¢òÂπ≤)",
        "options": [
           {{"label": "A", "text": "..."}},
           {{"label": "B", "text": "..."}}
        ],
        "answer": "String",
        "analysis": ""
      }}
    ]

    [ÂæÖÂ§ÑÁêÜÊñáÊú¨]
    {chunk}
    """

    for attempt in range(MAX_RETRIES):
        try:
            temp = 0.0 if attempt < 2 else 0.1

            response = client.chat.completions.create(
                model=AI_MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=temp,
                top_p=0.7,
                max_tokens=4000,
                timeout=API_TIMEOUT
            )
            content = response.choices[0].message.content

            content = repair_json(content)

            try:
                res = json.loads(content)
                if isinstance(res, list): return res
                if isinstance(res, dict): return [res]
                return []
            except json.JSONDecodeError:
                if attempt == MAX_RETRIES - 1:
                    print(f"      ‚ùå Chunk {index + 1} JSON Ëß£ÊûêÂΩªÂ∫ïÂ§±Ë¥•„ÄÇ")
                continue

        except Exception as e:
            # Âè™ÊúâË∂ÖÊó∂ÊâçÊâìÂç∞ÁÆÄÂçïÊó•Âøó
            # print(f"Wait {index}")
            wait_time = (2 ** attempt) + random.uniform(0, 1)
            time.sleep(wait_time)

    return []


def main():
    start_time = time.time()

    if not os.path.exists(INPUT_DIR): os.makedirs(INPUT_DIR)
    docx_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]

    if not docx_files:
        print("‚ùå input ÁõÆÂΩï‰∏∫Á©∫„ÄÇ")
        return

    target_output_file = get_next_output_filename()
    print(f"üöÄ Á®≥ÂÅ•Ê®°ÂºèÂêØÂä® | ÁõÆÊ†á: {target_output_file} | Á∫øÁ®ã: {MAX_WORKERS}")

    all_questions = []

    for filename in docx_files:
        print(f"\nüìÑ Â§ÑÁêÜÊñá‰ª∂: {filename}")
        raw_text = read_docx(os.path.join(INPUT_DIR, filename))
        if not raw_text: continue

        global_answers = extract_global_answers(raw_text)
        chunks = get_chunks(raw_text, CHUNK_SIZE, OVERLAP)

        tasks_args = [(chunk, i, len(chunks), global_answers) for i, chunk in enumerate(chunks)]
        chunk_added = 0

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # ÊâãÂä®Êèê‰∫§‰ªªÂä°ÔºåÊéßÂà∂ÂèëÂ∞ÑÈ¢ëÁéá
            futures = []
            for arg in tasks_args:
                futures.append(executor.submit(process_single_chunk, arg))
                # „ÄêÂÖ≥ÈîÆ„ÄëÊØèÂèëÂ∞Ñ‰∏ÄÈ¢óÂ≠êÂºπÔºåÂÅúÈ°ø 1 ÁßíÔºåÈò≤Ê≠¢Êã•Â†µ
                time.sleep(REQUEST_INTERVAL)

            # ‰ΩøÁî® tqdm ÁõëÊéß
            for future in tqdm(as_completed(futures), total=len(chunks), unit="ÂàáÁâá"):
                items = future.result()
                if items:
                    for item in items:
                        item['id'] = str(uuid.uuid4())
                        item['number'] = len(all_questions) + 1
                        item['chapter'] = filename.replace(".docx", "")
                        item['category'] = normalize_category(item.get('category', 'ÁªºÂêàÈ¢ò'))
                        if 'analysis' not in item: item['analysis'] = ""
                        all_questions.append(item)
                        chunk_added += 1

        print(f"   ‚úÖ Êú¨Êñá‰ª∂ÊèêÂèñ: {chunk_added} ÈÅì")

    final_json = {
        "version": "Universal-Stable-V3",
        "source": "GLM-4-Flash",
        "total_count": len(all_questions),
        "data": all_questions
    }

    with open(target_output_file, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)

    duration = time.time() - start_time
    msg = f"ÁîüÊàêÂÆåÊàêÔºÅ\nËÄóÊó∂: {duration:.1f}s\nÊñá‰ª∂: {target_output_file}\nÈ¢òÊï∞: {len(all_questions)}"
    print(f"\n‚ú® {msg}")

    with open("last_generated_file.txt", "w") as f:
        f.write(target_output_file)


if __name__ == "__main__":
    main()