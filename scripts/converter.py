import json
import os
import uuid
import hashlib
import time
import re
import requests
from docx import Document
from zhipuai import ZhipuAI
from concurrent.futures import ThreadPoolExecutor, as_completed

# ================= é…ç½®åŒºåŸŸ =================
INPUT_DIR = "input"
OUTPUT_DIR = "output"
OUTPUT_FILE = "questions_full.json"

# ä»ç¯å¢ƒå˜é‡è·å– Key
ZHIPU_API_KEY = os.getenv("ZHIPU_API_KEY")
PUSHPLUS_TOKEN = os.getenv("PUSHPLUS_TOKEN")

# ã€æ ¸å¿ƒè°ƒä¼˜å‚æ•°ã€‘
AI_MODEL_NAME = "glm-4-flash"  # æé€Ÿç‰ˆï¼šé«˜å¹¶å‘ã€ä½å»¶è¿Ÿã€é•¿ä¸Šä¸‹æ–‡
MAX_WORKERS = 8                # å¹¶å‘çº¿ç¨‹æ•°ï¼šFlashæ¨¡å‹æ”¯æŒè¾ƒé«˜å¹¶å‘ï¼Œ8-10æ˜¯å®‰å…¨åŒº
CHUNK_SIZE = 4000              # åˆ‡ç‰‡å¤§å°ï¼š4000å­—ç¬¦ï¼Œä¿è¯ä¸Šä¸‹æ–‡å®Œæ•´
OVERLAP = 500                  # é‡å åŒºåŸŸï¼šé˜²æ­¢é¢˜ç›®è¢«åˆ‡æ–­
AI_TEMPERATURE = 0.01          # æ¸©åº¦æä½ï¼šå¼ºåˆ¶AIâ€œæ­»æ¿â€ä¸€ç‚¹ï¼Œä¿è¯JSONæ ¼å¼æ­£ç¡®

# ===========================================

# åˆå§‹åŒ–å®¢æˆ·ç«¯
if not ZHIPU_API_KEY:
    print("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° ZHIPU_API_KEYï¼Œè¯·æ£€æŸ¥ GitHub Secrets æˆ–æœ¬åœ°ç¯å¢ƒå˜é‡ï¼")
    exit(1)

client = ZhipuAI(api_key=ZHIPU_API_KEY)

# æ ‡å‡†åˆ†ç±»ç™½åå•
STANDARD_CATEGORIES = {
    "å•é€‰é¢˜", "å¤šé€‰é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", 
    "åè¯è§£é‡Šé¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "è®¡ç®—é¢˜", "è¯æ˜é¢˜", "é…ä¼é¢˜"
}

def send_notification(title, content):
    """å‘é€å¾®ä¿¡é€šçŸ¥ (PushPlus)"""
    if not PUSHPLUS_TOKEN:
        print("âš ï¸ æœªé…ç½® PUSHPLUS_TOKENï¼Œè·³è¿‡å¾®ä¿¡é€šçŸ¥ã€‚")
        return
    
    url = "http://www.pushplus.plus/send"
    data = {
        "token": PUSHPLUS_TOKEN,
        "title": title,
        "content": content,
        "template": "html"
    }
    try:
        resp = requests.post(url, json=data, timeout=10)
        if resp.status_code == 200:
            print("âœ… å¾®ä¿¡é€šçŸ¥å·²å‘é€ï¼")
        else:
            print(f"âš ï¸ å¾®ä¿¡é€šçŸ¥å‘é€å¤±è´¥: {resp.text}")
    except Exception as e:
        print(f"âš ï¸ å¾®ä¿¡é€šçŸ¥ç½‘ç»œé”™è¯¯: {e}")

def read_docx(file_path):
    """é²æ£’çš„ Docx è¯»å–"""
    if not os.path.exists(file_path): return ""
    try:
        doc = Document(file_path)
        # è¿‡æ»¤ç©ºè¡Œï¼Œåˆå¹¶æ®µè½
        return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return ""

def get_chunks(text, chunk_size, overlap):
    """æ»‘åŠ¨çª—å£åˆ‡åˆ†"""
    chunks = []
    start = 0
    total_len = len(text)
    while start < total_len:
        end = min(start + chunk_size, total_len)
        chunks.append(text[start:end])
        if end == total_len: break
        start = end - overlap
    return chunks

def generate_fingerprint(q_obj):
    """ç”ŸæˆæŒ‡çº¹ç”¨äºå»é‡ (å†…å®¹+é€‰é¡¹)"""
    raw = q_obj.get("content", "") + str(q_obj.get("options", ""))
    return hashlib.md5(raw.encode('utf-8')).hexdigest()

def normalize_category(raw_cat):
    """å¼ºåŠ›å½’ä¸€åŒ–åˆ†ç±»åç§°"""
    if not raw_cat: return "ç»¼åˆé¢˜"
    cat = raw_cat.strip()
    
    # å…³é”®è¯æ˜ å°„
    if "å¤šé€‰" in cat or "ä¸å®šé¡¹" in cat: return "å¤šé€‰é¢˜"
    if "å•é€‰" in cat: return "å•é€‰é¢˜"
    if "åˆ¤æ–­" in cat or "æ˜¯é" in cat: return "åˆ¤æ–­é¢˜"
    if "å¡«ç©º" in cat: return "å¡«ç©ºé¢˜"
    if "åè¯" in cat: return "åè¯è§£é‡Šé¢˜"
    if "ç®€ç­”" in cat or "é—®ç­”" in cat or "è®ºè¿°" in cat: return "ç®€ç­”é¢˜"
    if "è®¡ç®—" in cat: return "è®¡ç®—é¢˜"
    if "è¯æ˜" in cat: return "è¯æ˜é¢˜"
    if "æ¡ˆä¾‹" in cat or "ç—…ä¾‹" in cat: return "æ¡ˆä¾‹åˆ†æé¢˜"
    if "é…ä¼" in cat or "è¿çº¿" in cat: return "é…ä¼é¢˜"

    # ç™½åå•ç›´é€š
    if cat in STANDARD_CATEGORIES: return cat
    
    # å…œåº•ï¼šå¼ºåˆ¶åŠ â€œé¢˜â€å­—
    if not cat.endswith("é¢˜"): return cat + "é¢˜"
    return cat

def extract_global_answers(full_text):
    """ç¬¬ä¸€æ­¥ï¼šæå–å…¨å±€ç­”æ¡ˆ (åˆ©ç”¨ Flash çš„é•¿ä¸Šä¸‹æ–‡)"""
    print("   ğŸ” [Step 1] æ­£åœ¨å…¨æ–‡æ¡£æ‰«ææå–å‚è€ƒç­”æ¡ˆ...")
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚è¯·é˜…è¯»ä¸‹é¢çš„æ–‡æ¡£å…¨æ–‡ï¼Œæå–å‡ºå…¶ä¸­çš„â€œå‚è€ƒç­”æ¡ˆâ€éƒ¨åˆ†ã€‚
    
    ã€è¦æ±‚ã€‘
    1. å¯»æ‰¾æ–‡æ¡£ä¸­é›†ä¸­çš„â€œç­”æ¡ˆé¡µâ€ã€â€œKeyâ€ã€â€œå‚è€ƒç­”æ¡ˆâ€éƒ¨åˆ†ã€‚
    2. å¦‚æœç­”æ¡ˆåˆ†æ•£åœ¨é¢˜ç›®åï¼Œä¹Ÿè¯·å°½åŠ›æå–ã€‚
    3. å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¿”å›"æ— ç­”æ¡ˆ"ã€‚
    4. **åªè¿”å›ç­”æ¡ˆæ–‡æœ¬**ï¼Œä¸è¦åŒ…å«é¢˜ç›®å†…å®¹ï¼Œä¸è¦åºŸè¯ã€‚
    """
    
    try:
        # æˆªå–å‰ 80k å­—ç¬¦ (Flash æ”¯æŒ 128kï¼Œç•™ä½™é‡ç»™ System Prompt)
        safe_text = full_text[:80000] 
        response = client.chat.completions.create(
            model=AI_MODEL_NAME,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": safe_text}
            ],
            temperature=0.1
        )
        answers = response.choices[0].message.content
        print(f"   âœ… å‚è€ƒç­”æ¡ˆæå–å®Œæ¯• (é•¿åº¦: {len(answers)} å­—ç¬¦)")
        return answers
    except Exception as e:
        print(f"   âš ï¸ æå–ç­”æ¡ˆå¤±è´¥ (å¯èƒ½æ˜¯æ–‡æ¡£è¿‡å¤§æˆ– API é”™è¯¯): {e}")
        return ""

def clean_json_string(content):
    """æ¸…æ´— AI è¿”å›çš„å­—ç¬¦ä¸²ï¼Œæå– JSON éƒ¨åˆ†"""
    try:
        # 1. å°è¯•å»é™¤ Markdown ä»£ç å—
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
        
        # 2. å°è¯•å¯»æ‰¾æœ€å¤–å±‚çš„ []
        start = content.find('[')
        end = content.rfind(']')
        if start != -1 and end != -1:
            content = content[start:end+1]
            
        return content.strip()
    except Exception:
        return content

def process_single_chunk(chunk_data):
    """[Step 2] å¹¶å‘å¤„ç†å•ä¸ªåˆ‡ç‰‡"""
    chunk, index, total, answer_key = chunk_data
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé€šç”¨è¯•é¢˜æå–åŠ©æ‰‹ã€‚è¯·å°†è¾“å…¥çš„æ–‡æœ¬ç‰‡æ®µè½¬æ¢ä¸ºä¸¥æ ¼çš„ JSON æ•°ç»„ã€‚
    
    ã€å‚è€ƒç­”æ¡ˆåº“ (ç”¨äºè‡ªåŠ¨å¡«ç©º)ã€‘
    ----------------
    {answer_key[:5000]}
    ----------------
    
    ã€ä»»åŠ¡è¦æ±‚ã€‘
    1. **è¯†åˆ«é¢˜ç›®**ï¼šä»æ–‡æœ¬ä¸­æå–å®Œæ•´çš„é¢˜ç›®ã€‚
    2. **å¿½ç•¥æ®‹ç¼º**ï¼šåˆ‡ç‰‡å¼€å¤´å’Œç»“å°¾å¦‚æœä¸å®Œæ•´ï¼Œç›´æ¥ä¸¢å¼ƒã€‚
    3. **åŒ¹é…ç­”æ¡ˆ**ï¼šæ ¹æ®é¢˜å·æˆ–å†…å®¹ï¼Œä»ä¸Šé¢çš„å‚è€ƒç­”æ¡ˆåº“ä¸­æ‰¾åˆ°å¯¹åº”çš„ç­”æ¡ˆå¡«å…¥ `answer` å­—æ®µã€‚å¦‚æœæ‰¾ä¸åˆ°ï¼Œç•™ç©ºã€‚
    4. **æ¨æ–­ç±»å‹**ï¼šè‡ªåŠ¨åˆ¤æ–­ `category` (å¦‚ å•é€‰é¢˜, åˆ¤æ–­é¢˜) å’Œ `type`ã€‚

    ã€è¾“å‡ºæ ¼å¼ (Strict JSON)ã€‘
    [
      {{
        "category": "å•é€‰é¢˜",
        "type": "SINGLE_CHOICE", 
        "content": "é¢˜å¹²å†…å®¹...",
        "options": [{{"label":"A", "text":"..."}}], 
        "answer": "A",
        "analysis": ""
      }}
    ]
    """
    
    try:
        response = client.chat.completions.create(
            model=AI_MODEL_NAME,
            messages=[{"role": "system", "content": prompt}, {"role": "user", "content": chunk}],
            temperature=AI_TEMPERATURE, # 0.01 ä¿è¯æ ¼å¼ç¨³å®š
            top_p=0.7,
            max_tokens=4000 # å…è®¸é•¿è¾“å‡º
        )
        raw_content = response.choices[0].message.content
        clean_content = clean_json_string(raw_content)
        
        return json.loads(clean_content)
        
    except json.JSONDecodeError:
        # å¸¸è§é”™è¯¯ï¼šAI æ²¡è¯´å®Œè¢«æˆªæ–­ï¼Œæˆ–è€…è¾“å‡ºäº†éæ³• JSON
        print(f"      âš ï¸ Chunk {index+1}: JSON è§£æå¤±è´¥ (å¯èƒ½æ˜¯å†…å®¹è¢«æˆªæ–­æˆ–æ ¼å¼é”™è¯¯)")
        return []
    except Exception as e:
        print(f"      âš ï¸ Chunk {index+1}: API è°ƒç”¨é”™è¯¯: {e}")
        return []

def main():
    start_time = time.time()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(INPUT_DIR): os.makedirs(INPUT_DIR)
    docx_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]
    
    if not docx_files:
        print("âŒ input ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ° .docx æ–‡ä»¶ã€‚")
        return
    
    all_questions = []
    seen_hashes = set()
    total_files = len(docx_files)
    
    print(f"ğŸš€ å¯åŠ¨ä»»åŠ¡ï¼šå‘ç° {total_files} ä¸ªæ–‡æ¡£ï¼Œä½¿ç”¨æ¨¡å‹ {AI_MODEL_NAME}ï¼Œå¹¶å‘æ•° {MAX_WORKERS}")

    for file_idx, filename in enumerate(docx_files):
        print(f"\nğŸ“„ [{file_idx+1}/{total_files}] å¤„ç†æ–‡ä»¶: {filename}")
        file_path = os.path.join(INPUT_DIR, filename)
        
        # è¯»å–
        raw_text = read_docx(file_path)
        if not raw_text: continue

        # 1. æå–ç­”æ¡ˆ (ä¸²è¡Œ)
        global_answers = extract_global_answers(raw_text)

        # 2. åˆ‡ç‰‡
        chunks = get_chunks(raw_text, CHUNK_SIZE, OVERLAP)
        print(f"   ğŸ“‚ åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µï¼Œå¼€å§‹ {MAX_WORKERS} çº¿ç¨‹å¹¶å‘å¤„ç†...")
        
        # 3. å¹¶å‘æå– (å¹¶è¡Œ)
        file_added_count = 0
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = [executor.submit(process_single_chunk, (chunk, i, len(chunks), global_answers)) 
                       for i, chunk in enumerate(chunks)]
            
            # å¤„ç†ç»“æœ
            for future in as_completed(futures):
                items = future.result()
                if items:
                    for item in items:
                        # å»é‡
                        fp = generate_fingerprint(item)
                        if fp in seen_hashes: continue
                        seen_hashes.add(fp)
                        
                        # æ ‡å‡†åŒ– & è¡¥å…¨
                        item['category'] = normalize_category(item.get('category', 'ç»¼åˆé¢˜'))
                        item['id'] = str(uuid.uuid4())
                        item['number'] = len(all_questions) + 1
                        item['chapter'] = filename.replace(".docx", "")
                        
                        all_questions.append(item)
                        file_added_count += 1
                        
        print(f"   âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæå–æœ‰æ•ˆé¢˜ç›®: {file_added_count} é“")

    # ä¿å­˜ç»“æœ
    final_json = {
        "version": "Universal-HighConcurrency",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "total_count": len(all_questions),
        "data": all_questions
    }
    
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    out_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
    
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)

    # ç»Ÿè®¡ä¸é€šçŸ¥
    duration = time.time() - start_time
    msg = (
        f"<b>ä»»åŠ¡å®ŒæˆæŠ¥å‘Š</b><br>"
        f"è€—æ—¶: {duration:.1f} ç§’<br>"
        f"å¤„ç†æ–‡æ¡£: {total_files} ä¸ª<br>"
        f"æå–é¢˜ç›®: {len(all_questions)} é“<br>"
        f"å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}<br>"
        f"æ¨¡å‹: {AI_MODEL_NAME}"
    )
    print(f"\nâœ¨ {msg.replace('<br>', '\n')}")
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {out_path}")
    
    send_notification("âœ… é¢˜åº“è½¬æ¢æˆåŠŸ", msg)

if __name__ == "__main__":
    main()