import json
import os
import uuid
import hashlib
import time
import requests
import random
from docx import Document
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
INPUT_DIR = "input"
OUTPUT_DIR = "output"
OUTPUT_FILE = "questions_full.json"

DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
PUSHPLUS_TOKEN = os.getenv("PUSHPLUS_TOKEN")

AI_BASE_URL = "https://api.deepseek.com"
AI_MODEL_NAME = "deepseek-chat"

# ã€ç‹‚æš´æ¨¡å¼é…ç½®ã€‘
# å¹¶å‘æ•°ï¼šç›´æ¥æ‹‰åˆ° 20ã€‚å¦‚æœé‡åˆ° 429 é”™è¯¯ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é€€é¿ï¼Œæ‰€ä»¥ä¸ç”¨æ€•
MAX_WORKERS = 20
CHUNK_SIZE = 2000
OVERLAP = 200
# é‡è¯•ï¼šæ­»ç£• 10 æ¬¡
MAX_RETRIES = 10
# è¶…æ—¶ï¼šç»™å®ƒ 180 ç§’ï¼ˆ3åˆ†é’Ÿï¼‰ï¼Œé˜²æ­¢å› ä¸ºDeepSeekç”Ÿæˆæ…¢è€Œè¢«æˆ‘ä»¬ä¸»åŠ¨æ–­å¼€
API_TIMEOUT = 180

# ===========================================

if not DEEPSEEK_API_KEY:
    print("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° DEEPSEEK_API_KEY")
    exit(1)

client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=AI_BASE_URL)

STANDARD_CATEGORIES = {
    "å•é€‰é¢˜", "å¤šé€‰é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜",
    "åè¯è§£é‡Šé¢˜", "ç®€ç­”é¢˜", "è®ºè¿°é¢˜",
    "è®¡ç®—é¢˜", "è¯æ˜é¢˜", "åº”ç”¨é¢˜", "ç¼–ç¨‹é¢˜",
    "é…ä¼é¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "ç»¼åˆé¢˜"
}


def send_notification(title, content):
    if not PUSHPLUS_TOKEN: return
    try:
        requests.post("http://www.pushplus.plus/send", json={
            "token": PUSHPLUS_TOKEN, "title": title, "content": content, "template": "html"
        }, timeout=5)
    except:
        pass


def read_docx(file_path):
    if not os.path.exists(file_path): return ""
    try:
        doc = Document(file_path)
        return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
    except:
        return ""


def get_chunks(text, chunk_size, overlap):
    chunks = []
    start = 0
    total_len = len(text)
    while start < total_len:
        end = min(start + chunk_size, total_len)
        chunks.append(text[start:end])
        if end == total_len: break
        start = end - overlap
    return chunks


def generate_fingerprint(q_obj):
    raw = q_obj.get("content", "") + str(q_obj.get("options", ""))
    return hashlib.md5(raw.encode('utf-8')).hexdigest()


def normalize_category(raw_cat):
    if not raw_cat: return "ç»¼åˆé¢˜"
    cat = raw_cat.strip()
    if "å¤šé€‰" in cat or "ä¸å®šé¡¹" in cat: return "å¤šé€‰é¢˜"
    if "å•é€‰" in cat or "A1" in cat or "A2" in cat: return "å•é€‰é¢˜"
    if "åˆ¤æ–­" in cat or "æ˜¯é" in cat: return "åˆ¤æ–­é¢˜"
    if "å¡«ç©º" in cat: return "å¡«ç©ºé¢˜"
    if "é…ä¼" in cat or "è¿çº¿" in cat or "B1" in cat: return "é…ä¼é¢˜"
    if "åè¯" in cat: return "åè¯è§£é‡Šé¢˜"
    if "ç®€ç­”" in cat or "é—®ç­”" in cat: return "ç®€ç­”é¢˜"
    if "è®¡ç®—" in cat: return "è®¡ç®—é¢˜"
    if "ç¼–ç¨‹" in cat or "ä»£ç " in cat: return "ç¼–ç¨‹é¢˜"
    if "åº”ç”¨" in cat: return "åº”ç”¨é¢˜"
    if "è¯æ˜" in cat: return "è¯æ˜é¢˜"
    if "æ¡ˆä¾‹" in cat or "ç—…ä¾‹" in cat: return "æ¡ˆä¾‹åˆ†æé¢˜"

    if cat in STANDARD_CATEGORIES: return cat
    if not cat.endswith("é¢˜"): return cat + "é¢˜"
    return cat


def repair_json(json_str):
    json_str = json_str.strip()
    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ Markdown ä»£ç å—
    if "```json" in json_str:
        json_str = json_str.split("```json")[1].split("```")[0]
    elif "```" in json_str:
        json_str = json_str.split("```")[1].split("```")[0]
    json_str = json_str.strip()

    if not json_str.endswith("]"):
        last_brace = json_str.rfind("}")
        if last_brace != -1:
            json_str = json_str[:last_brace + 1] + "]"
    return json_str


def extract_global_answers(full_text):
    print("   ğŸ” [Step 1] DeepSeek æ­£åœ¨å…¨æ–‡æ‰«æå‚è€ƒç­”æ¡ˆ...")
    # æˆªå–å¤´å°¾ï¼Œæœ€å¤§åŒ–è¦†ç›–ç‡
    safe_text = full_text[-50000:] + "\n" + full_text[:20000]
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ†æå¸ˆã€‚è¯·æ‰«ææ–‡æ¡£ï¼Œæå–æ‰€æœ‰â€œå‚è€ƒç­”æ¡ˆâ€éƒ¨åˆ†ã€‚
    è¦æ±‚ï¼šåªæå–ç­”æ¡ˆæ–‡æœ¬ï¼ˆå¦‚ 1.A 2.Bï¼‰ï¼ŒæŒ‰é¡ºåºæ’åˆ—ï¼Œåˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨ã€‚
    å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›â€œæ— â€ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=AI_MODEL_NAME,
            messages=[{"role": "system", "content": prompt}, {"role": "user", "content": safe_text}],
            temperature=0.1,
            timeout=120
        )
        ans = response.choices[0].message.content
        print(f"   âœ… å‚è€ƒç­”æ¡ˆåº“æ„å»ºå®Œæˆ (é•¿åº¦: {len(ans)} å­—ç¬¦)")
        return ans
    except Exception as e:
        print(f"   âš ï¸ ç­”æ¡ˆæå–å¤±è´¥: {e}")
        return ""


def process_single_chunk(args):
    chunk, index, total, answer_key = args

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªè¯•é¢˜æå–ä¸“å®¶ã€‚è¯·å°†æ–‡æœ¬åˆ‡ç‰‡è½¬æ¢ä¸º JSON æ•°ç»„ã€‚

    ### å…¨å±€å‚è€ƒç­”æ¡ˆåº“
    {answer_key[:15000]} ... 

    ### ä»»åŠ¡
    1. **æå–é¢˜ç›®**ï¼šå¿½ç•¥åˆ‡ç‰‡é¦–å°¾ä¸å®Œæ•´å¥å­ã€‚
    2. **é…å¯¹ç­”æ¡ˆ**ï¼šæ ¹æ®é¢˜å·å»ç­”æ¡ˆåº“æŸ¥æ‰¾ï¼Œæˆ–ä½¿ç”¨é¢˜ç›®è‡ªå¸¦ç­”æ¡ˆã€‚**å¿…é¡»å¡«å…¥ answer å­—æ®µ**ã€‚
    3. **æ¨æ–­ç±»å‹**ï¼šè‡ªåŠ¨åˆ¤æ–­ category å’Œ typeã€‚

    ### JSON æ ¼å¼
    [
      {{
        "category": "å•é€‰é¢˜",
        "type": "SINGLE_CHOICE", 
        "content": "é¢˜å¹²...", 
        "options": [{{"label":"A", "text":"..."}}], 
        "answer": "A",
        "analysis": ""
      }}
    ]
    """

    last_error = None
    for attempt in range(MAX_RETRIES):
        try:
            # åŠ¨æ€æ¸©åº¦ï¼šé‡è¯•æ¬¡æ•°è¶Šå¤šï¼Œæ¸©åº¦ç•¥å¾®å‡é«˜ï¼Œé˜²æ­¢æ­»å¾ªç¯
            temp = 0.0 if attempt < 2 else 0.2

            response = client.chat.completions.create(
                model=AI_MODEL_NAME,
                messages=[{"role": "system", "content": prompt}, {"role": "user", "content": chunk}],
                temperature=temp,
                max_tokens=4000,
                timeout=API_TIMEOUT  # è®¾ç½®è¶…æ—¶
            )
            content = response.choices[0].message.content

            # æ¸…æ´— & ä¿®å¤
            content = repair_json(content)

            try:
                return json.loads(content)
            except json.JSONDecodeError:
                if attempt == MAX_RETRIES - 1:
                    print(f"      âŒ Chunk {index + 1} JSON è§£æå¤±è´¥: {content[:50]}...")
                continue  # é‡è¯•

        except Exception as e:
            last_error = e
            # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s, 8s...
            wait_time = (2 ** attempt) + random.uniform(0, 1)
            # åªæœ‰æœ€åå‡ æ¬¡é‡è¯•æ‰æ‰“å°æ—¥å¿—ï¼Œé¿å…åˆ·å±
            if attempt > 2:
                print(f"      âš ï¸ Chunk {index + 1} é‡è¯• ({attempt + 1}/{MAX_RETRIES}): {e}")
            time.sleep(wait_time)

    # å½»åº•å¤±è´¥ï¼Œè¿”å› None ä»¥ä¾¿åç»­è¯†åˆ«
    return None


def main():
    start_time = time.time()

    if not os.path.exists(INPUT_DIR): os.makedirs(INPUT_DIR)
    docx_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]

    if not docx_files:
        print("âŒ input ç›®å½•ä¸ºç©ºã€‚")
        return

    all_questions = []
    seen_hashes = set()

    print(f"ğŸš€ DeepSeek ç‹‚æš´æ¨¡å¼ | å¹¶å‘: {MAX_WORKERS} | é‡è¯•: {MAX_RETRIES}æ¬¡ | æ–‡æ¡£: {len(docx_files)}")

    for filename in docx_files:
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
        raw_text = read_docx(os.path.join(INPUT_DIR, filename))
        if not raw_text: continue

        global_answers = extract_global_answers(raw_text)
        chunks = get_chunks(raw_text, CHUNK_SIZE, OVERLAP)

        # ä»»åŠ¡é˜Ÿåˆ—
        # ä½¿ç”¨å­—å…¸å­˜å‚¨ task: (chunk_data) æ–¹ä¾¿é‡è¯•
        tasks_map = {i: (chunks[i], i, len(chunks), global_answers) for i in range(len(chunks))}
        failed_chunks = []

        # === Round 1: å¹¶å‘å¤„ç† ===
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # æäº¤ä»»åŠ¡
            future_to_idx = {
                executor.submit(process_single_chunk, tasks_map[i]): i
                for i in tasks_map
            }

            # è¿›åº¦æ¡
            for future in tqdm(as_completed(future_to_idx), total=len(chunks), unit="åˆ‡ç‰‡"):
                idx = future_to_idx[future]
                result = future.result()

                if result is None:
                    # è®°å½•å¤±è´¥çš„ Chunk
                    failed_chunks.append(idx)
                else:
                    # æˆåŠŸå¤„ç†
                    for item in result:
                        fp = generate_fingerprint(item)
                        if fp in seen_hashes: continue
                        seen_hashes.add(fp)
                        item['category'] = normalize_category(item.get('category', 'ç»¼åˆé¢˜'))
                        item['id'] = str(uuid.uuid4())
                        item['number'] = len(all_questions) + 1
                        item['chapter'] = filename.replace(".docx", "")
                        all_questions.append(item)

        # === Round 2: å¤±è´¥åˆ‡ç‰‡è¡¥æ•‘ (ä¸²è¡Œ/ä½å¹¶å‘æ…¢é€Ÿé‡è¯•) ===
        if failed_chunks:
            print(f"\nâš ï¸ å‘ç° {len(failed_chunks)} ä¸ªå¤±è´¥åˆ‡ç‰‡ï¼Œæ­£åœ¨è¿›è¡Œæ…¢é€Ÿè¡¥æ•‘...")
            for idx in failed_chunks:
                print(f"   ğŸš‘ è¡¥æ•‘ Chunk {idx + 1}...")
                # è¡¥æ•‘æ—¶ç»™äºˆæ›´é«˜æ¸©åº¦ï¼Œç¢°è¿æ°”
                retry_args = tasks_map[idx]
                # è¿™é‡Œæˆ‘ä»¬ç¨å¾®ä¿®æ”¹ä¸€ä¸‹é‡è¯•é€»è¾‘ï¼Œæˆ–è€…ç›´æ¥é€’å½’è°ƒç”¨ process_single_chunk
                # ç®€å•èµ·è§ï¼Œç›´æ¥å†æ¬¡è°ƒç”¨
                result = process_single_chunk(retry_args)

                if result:
                    print(f"      âœ… è¡¥æ•‘æˆåŠŸï¼")
                    for item in result:
                        fp = generate_fingerprint(item)
                        if fp in seen_hashes: continue
                        seen_hashes.add(fp)
                        item['category'] = normalize_category(item.get('category', 'ç»¼åˆé¢˜'))
                        item['id'] = str(uuid.uuid4())
                        item['number'] = len(all_questions) + 1
                        item['chapter'] = filename.replace(".docx", "")
                        all_questions.append(item)
                else:
                    print(f"      âŒ è¡¥æ•‘å¤±è´¥ï¼Œæ”¾å¼ƒè¯¥åˆ‡ç‰‡ã€‚")

    final_json = {
        "version": "DeepSeek-Berserk",
        "total_count": len(all_questions),
        "data": all_questions
    }

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    out_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)

    duration = time.time() - start_time
    msg = f"DeepSeek ç‹‚æš´å¤„ç†å®Œæˆï¼\nè€—æ—¶: {duration:.1f}s\né¢˜ç›®: {len(all_questions)}\nå¹¶å‘: {MAX_WORKERS}"
    print(f"\nâœ¨ {msg}")
    send_notification("âœ… é¢˜åº“è½¬æ¢æˆåŠŸ", msg.replace('\n', '<br>'))


if __name__ == "__main__":
    main()