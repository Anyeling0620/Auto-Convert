import json
import os
import uuid
import hashlib
from docx import Document
from zhipuai import ZhipuAI

# === é…ç½®åŒºåŸŸ ===
INPUT_DIR = "input"
OUTPUT_DIR = "output"
OUTPUT_FILE = "questions_full.json"
ZHIPU_API_KEY = os.getenv("ZHIPU_API_KEY")

client = ZhipuAI(api_key=ZHIPU_API_KEY)

# æ ‡å‡†åˆ†ç±»ç™½åå•
STANDARD_CATEGORIES = {
    "å•é€‰é¢˜", "å¤šé€‰é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜", 
    "åè¯è§£é‡Šé¢˜", "æ¡ˆä¾‹åˆ†æé¢˜", "è®¡ç®—é¢˜", "è¯æ˜é¢˜", "é…ä¼é¢˜"
}

def read_docx(file_path):
    if not os.path.exists(file_path): return ""
    doc = Document(file_path)
    return "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])

def get_chunks(text, chunk_size=1500, overlap=200):
    """åˆ‡ç‰‡å‡½æ•°"""
    chunks = []
    start = 0
    total_len = len(text)
    while start < total_len:
        end = min(start + chunk_size, total_len)
        chunks.append(text[start:end])
        if end == total_len: break
        start = end - overlap
    return chunks

def generate_fingerprint(q_obj):
    raw = q_obj.get("content", "") + str(q_obj.get("options", ""))
    return hashlib.md5(raw.encode('utf-8')).hexdigest()

def normalize_category(raw_cat):
    if not raw_cat: return "ç»¼åˆé¢˜"
    cat = raw_cat.strip()
    if "å¤šé€‰" in cat or "ä¸å®šé¡¹" in cat: return "å¤šé€‰é¢˜"
    if "å•é€‰" in cat: return "å•é€‰é¢˜"
    if "åˆ¤æ–­" in cat or "æ˜¯é" in cat: return "åˆ¤æ–­é¢˜"
    if "å¡«ç©º" in cat: return "å¡«ç©ºé¢˜"
    if "åè¯" in cat: return "åè¯è§£é‡Šé¢˜"
    if "ç®€ç­”" in cat or "é—®ç­”" in cat or "è®ºè¿°" in cat: return "ç®€ç­”é¢˜"
    if cat in STANDARD_CATEGORIES: return cat
    if not cat.endswith("é¢˜"): return cat + "é¢˜"
    return cat

# === [æ ¸å¿ƒæ–°å¢] ç¬¬ä¸€æ­¥ï¼šæå–å…¨å±€ç­”æ¡ˆ ===
def extract_global_answers(full_text):
    """
    è®© AI é€šè¯»å…¨æ–‡ï¼Œåªæå–ç­”æ¡ˆéƒ¨åˆ†ã€‚
    GLM-4-Flash æ”¯æŒ 128k ä¸Šä¸‹æ–‡ï¼Œè¯»æ•´ä¸ªæ–‡æ¡£æ²¡é—®é¢˜ã€‚
    """
    print("   ğŸ” Scanning document for Answer Key...")
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚è¯·é˜…è¯»ä¸‹é¢çš„æ–‡æ¡£å…¨æ–‡ï¼Œæå–å‡ºå…¶ä¸­çš„â€œç­”æ¡ˆâ€éƒ¨åˆ†ã€‚
    
    ã€è¦æ±‚ã€‘
    1. å¦‚æœæ–‡æ¡£åŒ…å«é›†ä¸­çš„â€œç­”æ¡ˆé¡µâ€æˆ–â€œå‚è€ƒç­”æ¡ˆâ€éƒ¨åˆ†ï¼Œè¯·å°†è¿™éƒ¨åˆ†å†…å®¹åŸæ ·æå–å‡ºæ¥ã€‚
    2. å¦‚æœç­”æ¡ˆåˆ†æ•£åœ¨é¢˜ç›®åï¼Œè¯·æå–å‡ºæ‰€æœ‰èƒ½æ‰¾åˆ°çš„ç­”æ¡ˆä¿¡æ¯ã€‚
    3. å¦‚æœæ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¿”å›"æ— ç­”æ¡ˆ"ã€‚
    4. **åªè¿”å›ç­”æ¡ˆæ–‡æœ¬**ï¼Œä¸è¦åŒ…å«é¢˜ç›®å†…å®¹ï¼Œä¸è¦åºŸè¯ã€‚
    """
    
    try:
        # æˆªå–å‰ 60000 å­—ç¬¦ï¼ˆé˜²æ­¢æç«¯è¶…é•¿ï¼Œä¸€èˆ¬æ–‡æ¡£è¶³å¤Ÿäº†ï¼‰
        safe_text = full_text[:60000] 
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": safe_text}
            ],
            temperature=0.1
        )
        answers = response.choices[0].message.content
        print(f"   âœ… Answer Key extracted (Length: {len(answers)} chars)")
        return answers
    except Exception as e:
        print(f"   âš ï¸ Failed to extract answers: {e}")
        return ""

# === [ä¿®æ”¹] ç¬¬äºŒæ­¥ï¼šæºå¸¦ç­”æ¡ˆæå–é¢˜ç›® ===
def call_glm4_with_answers(text_chunk, answer_key):
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé€šç”¨è¯•é¢˜æå–åŠ©æ‰‹ã€‚è¯·å°†è¾“å…¥çš„æ–‡æœ¬ç‰‡æ®µè½¬æ¢ä¸ºä¸¥æ ¼çš„ JSON æ•°ç»„ã€‚
    
    ã€å‚è€ƒç­”æ¡ˆåº“ã€‘
    è¿™æ˜¯æœ¬æ–‡æ¡£çš„ç­”æ¡ˆéƒ¨åˆ†ï¼Œè¯·æ ¹æ®é¢˜ç›®ç¼–å·æˆ–å†…å®¹ï¼Œå°è¯•ä¸ºä¸‹é¢çš„é¢˜ç›®åŒ¹é…ç­”æ¡ˆï¼š
    ----------------
    {answer_key[:5000]} 
    (å¦‚æœç­”æ¡ˆå¤ªé•¿å·²æˆªæ–­ï¼Œè¯·å°½åŠ›åŒ¹é…)
    ----------------
    
    ã€æ ¸å¿ƒä»»åŠ¡ã€‘
    1. æå–æ–‡æœ¬ç‰‡æ®µä¸­çš„å®Œæ•´é¢˜ç›®ã€‚
    2. **è‡ªåŠ¨é…å¯¹ç­”æ¡ˆ**ï¼šåˆ©ç”¨ä¸Šé¢çš„å‚è€ƒç­”æ¡ˆåº“å¡«å…¥ `answer` å­—æ®µã€‚å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ç­”æ¡ˆï¼Œç•™ç©ºã€‚
    3. å¿½ç•¥åˆ‡ç‰‡å¼€å¤´ç»“å°¾çš„ä¸å®Œæ•´å¥å­ã€‚
    
    ã€è¾“å‡ºæ ¼å¼ã€‘
    Strict JSON Array ONLY:
    [
      {{
        "category": "å•é€‰é¢˜",
        "type": "SINGLE_CHOICE",
        "content": "é¢˜å¹²",
        "options": [{{"label":"A", "text":"..."}}], 
        "answer": "A",
        "analysis": ""
      }}
    ]
    """
    
    try:
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": text_chunk}
            ],
            temperature=0.1,
            top_p=0.7,
            max_tokens=4000
        )
        content = response.choices[0].message.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        return json.loads(content.strip())
    except Exception as e:
        print(f"   âš ï¸ Chunk parse error: {e}")
        return []

def main():
    docx_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(".docx")]
    if not docx_files:
        print("âŒ No .docx files found.")
        return
    
    all_questions = []
    seen_hashes = set()
    
    for filename in docx_files:
        file_path = os.path.join(INPUT_DIR, filename)
        print(f"\nğŸš€ Processing: {filename}")
        
        raw_text = read_docx(file_path)
        if not raw_text: continue

        # 1. å…ˆæå–å…¨å±€ç­”æ¡ˆ (åˆ©ç”¨ GLM-4 é•¿ä¸Šä¸‹æ–‡)
        global_answers = extract_global_answers(raw_text)

        # 2. å†åˆ‡ç‰‡æå–é¢˜ç›® (æŠŠç­”æ¡ˆä¼ è¿›å»)
        chunks = get_chunks(raw_text, chunk_size=1500, overlap=300)
        print(f"   ğŸ“‚ Split into {len(chunks)} chunks.")
        
        for i, chunk in enumerate(chunks):
            print(f"   âš¡ Analyzing chunk {i+1}/{len(chunks)}...")
            
            # è°ƒç”¨å¸¦ç­”æ¡ˆçš„æå–å‡½æ•°
            items = call_glm4_with_answers(chunk, global_answers)
            
            new_count = 0
            for item in items:
                fp = generate_fingerprint(item)
                if fp in seen_hashes: continue
                seen_hashes.add(fp)
                
                item['category'] = normalize_category(item.get('category', 'ç»¼åˆé¢˜'))
                item['id'] = str(uuid.uuid4())
                item['number'] = len(all_questions) + 1
                item['chapter'] = filename.replace(".docx", "")
                
                all_questions.append(item)
                new_count += 1
            print(f"      -> Added {new_count} questions.")

    final_json = {
        "version": "Universal-V3-WithAnswers",
        "source": "Smart Import",
        "total_count": len(all_questions),
        "data": all_questions
    }
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    out_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(final_json, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… All Done! Saved to: {out_path}")

if __name__ == "__main__":
    main()